\documentclass[a4paper,onecolumn,oneside]{article}

\usepackage{hyperref}
\usepackage{parskip}
\usepackage{graphicx}
\usepackage{color}
\usepackage{subfigure}
\usepackage{amssymb}
\usepackage{amsmath}

\DeclareMathOperator{\avg}{avg}

\title{Distributed Systems\\Assignment 1}
\author{Clemens Wolff (s0942284)}
\date{March 13, 2014}

\begin{document}
\maketitle

\section*{Question 1}
\section*{Question 2}

Starvation occurs when a thread that tried to enter its critical section (CS)
never actually did end up entering its critical section at any point in time.

An example of a system that leads to starvation is any system using the mutual
exclusion algorithm proposed by Dijkstra in \cite{dijkstra2001}.  The algorithm
works as follows.  When two processes attempt to enter the CS at the same time,
the process who most recently was in the CS is given priority.  This will lead
to starved processes if the same process is interested in the CS all the time
\cite[Theorem~5.1]{alagarsamy2003}.

Another system that leads to starvation is any system using the generalised
Peterson's mutual exclusion algorithm presented by \cite{hofri1990} with $N \geq
3$ processes.  The algorithm works as follows.  There are $N$ ``waiting rooms''
through which processes that wish to enter the CS have to advance.  Every
waiting room allows at least one process to advance and keeps one process
waiting. Assume there are three processes $p_1$, $p_2$ and $p_3$.  $p_2$
requests the CS, then $p_3$ requests the CS and then $p_1$ requests the CS.
Next assume that $p_1$ runs and then $p_3$ runs. $p_3$ now is eligible for the
CS again.  Assume that $p_3$ requests the CS again (and that $p_2$ requests the
CS after $p_3$).  $p_2$ and $p_3$ now take turns requesting the CS and running.
$p_1$ is starved \cite[Figure~1]{griffault2014}.

\section*{Question 3}

\textbf{Algorithm:}  Every node $p$ without children in the BFS tree $T$ of the
graph $G$ sends its value of $f.p$ to its parent $P^p$.  Every parent $P^j$
receives values
$f.p^1\ldots f.p^{k^{P^j}}$ where $k^{P^j}$ is the number of children of $P^j$.
The parents sends the values
$$\mathfrak{M}^{P^{P^j}} = \max\left\{f.p_1\ldots f.p_k^{P^j}\right\},$$
$$\mathfrak{S}^{P^{P^j}} = \sum\limits_{i=1}^{k^{P^j}} f.p_i\;\mathrm{and}$$
$$\mathfrak{K}^{P^{P^j}} = k + 1$$
to its own parent $P^{P^j}$.
Repeat until the root node $r$ of $T$ is reached.  The maximum value of $f$ in
the graph is the maximum of the values that the root node receives and the value
of $f$ at the root node:
$$\max\left\{p.f \mid p \in G\right\} = \max(r.f, \mathfrak{M}^r).$$
Similarly, the average value
of $f$ in the graph is:
$$\avg\left\{p.f \mid p \in G\right\} = {r.f + \mathfrak{S}^r \over \mathfrak{K}^r + 1}.$$
The root node now uses the BFS tree to distribute the maximum and average values
to the tree (i.e.\ the value is sent to the children of $r$ and those children
forward the value to their children recursively until the leaves of the tree are
reached).

\textbf{Time complexity:}  It takes at most $N$ time to send a message from
leaves to root in a BFS tree with $N$ items.  Collecting the tree-maximum
tree-sum therefore takes at most $N$ time and distributing the values back in
the tree takes at most $N$ time.  Therefore the overall time complexity is
$O(N)$.

\textbf{Message complexity:}  Every node in the tree only sends messages to its
children or parent.  This means that every node sends at most one message when
collecting or distributing the tree-maximum and tree-sum.  Therefore the overall
message complexity is $O(N)$.

\section*{Question 4}

The diameter of a graph is the longest shortest path in the graph (i.e.\ the
length of the shortest path between the most distant nodes).

Table~\ref{tbl:weighted-paths} shows that the diameter of the weighted graph is
8.  The path realising this diameter is $d\rightarrow h\rightarrow l\rightarrow
m$.

Table~\ref{tbl:unweighted-paths} shows that the diameter of the unweighted graph
is 5.  One path realising this diameter is $e\rightarrow a\rightarrow
c\rightarrow g\rightarrow l\rightarrow m$.  Another path realising this diameter
is $e\rightarrow a\rightarrow c\rightarrow g\rightarrow l\rightarrow m$.

\begin{table}
\begin{subtable}
\centering
\begin{tabular}{c || c c c c c c c c c c c c}
 & a& b& c& d& e& f& g& h& i& k& l& m\\
\hline \hline
a& 0& 2& 1& 4& 0& 2& 0& 3& 0& 3& 3& 5\\
b&  & 0& 2& 2& 2& 1& 1& 4& 1& 4& 4& 6\\
c&  &  & 0& 4& 1& 1&-1& 2&-1& 2& 2& 4\\
d&  &  &  & 0& 4& 5& 3& 3& 3& 6& 6& \colorbox{yellow}{8}\\
e&  &  &  &  & 0& 2& 0& 3& 0& 3& 3& 5\\
f&  &  &  &  &  & 0&-2& 1&-2& 1& 1& 3\\
g&  &  &  &  &  &  & 0& 3& 0& 3& 3& 5\\
h&  &  &  &  &  &  &  & 0& 3& 6& 3& 5\\
i&  &  &  &  &  &  &  &  & 0& 3& 3& 5\\
k&  &  &  &  &  &  &  &  &  & 0& 3& 2\\
l&  &  &  &  &  &  &  &  &  &  & 0& 2\\
m&  &  &  &  &  &  &  &  &  &  &  & 0\\
\end{tabular}
\caption{Length of shortest paths between nodes in weighted graph.}
\label{tbl:weighted-paths}
\end{subtable}
\qquad

\begin{subtable}
\centering
\begin{tabular}{c || c c c c c c c c c c c c}
 & a& b& c& d& e& f& g& h& i& k& l& m\\
\hline \hline
a& 0& 1& 1& 2& 1& 2& 2& 3& 3& 4& 3& 4\\
b&  & 0& 1& 1& 2& 2& 2& 2& 3& 4& 3& 4\\
c&  &  & 0& 2& 2& 1& 1& 2& 2& 3& 2& 3\\
d&  &  &  & 0& 3& 3& 2& 1& 3& 3& 2& 3\\
e&  &  &  &  & 0& 3& 3& 4& 4& \colorbox{yellow}{5}& 4& \colorbox{yellow}{5}\\
f&  &  &  &  &  & 0& 2& 3& 1& 2& 3& 3\\
g&  &  &  &  &  &  & 0& 1& 1& 2& 1& 2\\
h&  &  &  &  &  &  &  & 0& 2& 2& 1& 2\\
i&  &  &  &  &  &  &  &  & 0& 1& 2& 2\\
k&  &  &  &  &  &  &  &  &  & 0& 1& 1\\
l&  &  &  &  &  &  &  &  &  &  & 0& 1\\
m&  &  &  &  &  &  &  &  &  &  &  & 0\\
\end{tabular}
\caption{Length of shortest paths between nodes in unweighted graph.}
\label{tbl:unweighted-paths}
\end{subtable}
\end{table}

\clearpage

\begin{thebibliography}{32}

\bibitem{dijkstra2001} Dijkstra, Edsger W. ``Solution of a problem in concurrent
programming control.'' \emph{Pioneers and Their Contributions to Software
Engineering.} Springer Berlin Heidelberg, 2001. 289-294.

\bibitem{alagarsamy2003} Alagarsamy, K. ``Some myths about famous mutual
exclusion algorithms.'' \emph{ACM SIGACT News} 34.3 (2003): 94-103.

\bibitem{hofri1990} Hofri, Micha. ``Proof of a mutual exclusion algorithm --- a
classic example.'' \emph{ACM SIGOPS Operating Systems Review} 24.1 (1990):
18-22.

\bibitem{griffault2014} Griffault, A., and G. Point. ``Proof of Petersonâ€™s
algorithm for mutual exclusion.'' (2014).

\end{thebibliography}

\end{document}
